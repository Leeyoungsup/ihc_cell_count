{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f827039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import yaml\n",
    "from torch.utils import data\n",
    "# 개별 json 라벨 파일을 이용해 학습 데이터 리스트 생성\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from nets import nn\n",
    "from utils import util\n",
    "from utils.dataset import Dataset\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76e71dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 파라미터:\n",
      "클래스 이름: {0: 'nucleus'}\n",
      "클래스 수: 1\n",
      "첫 번째 데이터셋에서 찾은 라벨 파일: 135개\n",
      "두 번째 데이터셋에서 찾은 라벨 파일: 344개\n",
      "\n",
      "총 데이터:\n",
      "이미지 파일: 479개\n",
      "라벨 세트: 479개\n",
      "\n",
      "라벨 분포:\n",
      "총 라벨 수: 929007\n",
      "클래스 1: 929007개\n",
      "빈 라벨 세트: 2개\n",
      "Warning: 빈 라벨 세트가 있습니다. 이는 loss가 0이 되는 원인이 될 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 및 데이터 경로 설정\n",
    "with open('utils/Binary_args.yaml', errors='ignore') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "print(\"모델 파라미터:\")\n",
    "print(f\"클래스 이름: {params['names']}\")\n",
    "print(f\"클래스 수: {len(params['names'])}\")\n",
    "\n",
    "label_dir = '../../data/IGNITE/annotations/pdl1/binary_individual/'\n",
    "image_dir = '../../data/IGNITE/images/pdl1/nuclei/'\n",
    "\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, '*.json')))\n",
    "filenames = []\n",
    "labels = []\n",
    "\n",
    "print(f\"첫 번째 데이터셋에서 찾은 라벨 파일: {len(label_files)}개\")\n",
    "\n",
    "for label_file in label_files:\n",
    "    with open(label_file) as f:\n",
    "        data1 = json.load(f)\n",
    "    img_path = os.path.join(image_dir, data1['image']['file_name'])\n",
    "    if os.path.exists(img_path):\n",
    "        filenames.append(img_path)\n",
    "        temp_labels = []\n",
    "        for i in range(len(data1['annotations'])):\n",
    "            # 모든 nucleus를 클래스 1로 통일\n",
    "            temp_labels.append([1, int(data1['annotations'][i]['bbox'][0]),\n",
    "                         int(data1['annotations'][i]['bbox'][1]),int(data1['annotations'][i]['bbox'][2]),int(data1['annotations'][i]['bbox'][3])])\n",
    "            \n",
    "        labels.append(temp_labels)\n",
    "        \n",
    "label_dir = '../../data/IGNITE/annotations/pdl1/individual/'\n",
    "image_dir = '../../data/IGNITE/images/pdl1/pdl1/'\n",
    "\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, '*.json')))\n",
    "print(f\"두 번째 데이터셋에서 찾은 라벨 파일: {len(label_files)}개\")\n",
    "\n",
    "for label_file in label_files:\n",
    "    with open(label_file) as f:\n",
    "        data1 = json.load(f)\n",
    "    img_path = os.path.join(image_dir, data1['image']['file_name'])\n",
    "    if os.path.exists(img_path):\n",
    "        filenames.append(img_path)\n",
    "        temp_labels = []\n",
    "        for i in range(len(data1['annotations'])):\n",
    "            # 모든 nucleus를 클래스 1로 통일 (이미 1로 설정되어 있음)\n",
    "            temp_labels.append([1, int(data1['annotations'][i]['bbox'][0]),\n",
    "                         int(data1['annotations'][i]['bbox'][1]),int(data1['annotations'][i]['bbox'][2]),int(data1['annotations'][i]['bbox'][3])])\n",
    "        labels.append(temp_labels)\n",
    "\n",
    "print(f\"\\n총 데이터:\")\n",
    "print(f\"이미지 파일: {len(filenames)}개\")\n",
    "print(f\"라벨 세트: {len(labels)}개\")\n",
    "\n",
    "# 라벨 분포 확인\n",
    "total_labels = 0\n",
    "class_counts = {}\n",
    "for label_set in labels:\n",
    "    total_labels += len(label_set)\n",
    "    for label in label_set:\n",
    "        class_id = label[0]\n",
    "        if class_id not in class_counts:\n",
    "            class_counts[class_id] = 0\n",
    "        class_counts[class_id] += 1\n",
    "\n",
    "print(f\"\\n라벨 분포:\")\n",
    "print(f\"총 라벨 수: {total_labels}\")\n",
    "for class_id, count in sorted(class_counts.items()):\n",
    "    print(f\"클래스 {class_id}: {count}개\")\n",
    "\n",
    "# 빈 라벨 세트 확인\n",
    "empty_label_count = sum(1 for label_set in labels if len(label_set) == 0)\n",
    "print(f\"빈 라벨 세트: {empty_label_count}개\")\n",
    "\n",
    "if empty_label_count > 0:\n",
    "    print(\"Warning: 빈 라벨 세트가 있습니다. 이는 loss가 0이 되는 원인이 될 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c0666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터: 479\n",
      "훈련 데이터: 431\n",
      "검증 데이터: 48\n",
      "\n",
      "샘플 데이터 확인:\n",
      "이미지 크기: torch.Size([3, 512, 512])\n",
      "클래스 수: 10\n",
      "바운딩 박스 수: 10\n",
      "클래스 범위: 0 ~ 0\n",
      "바운딩 박스 좌표 범위: x_center=0.010~0.887, y_center=0.025~0.936\n",
      "바운딩 박스 크기 범위: width=0.031~0.031, height=0.031~0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.3'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:251: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    }
   ],
   "source": [
    "class custom_dataset(data.Dataset):\n",
    "    def __init__(self, filenames, input_size, params, augment, labels=None, image_infos=None):\n",
    "        self.params = params\n",
    "        self.mosaic = augment\n",
    "        self.augment = augment\n",
    "        self.input_size = input_size\n",
    "        if labels is not None:\n",
    "            self.labels = labels\n",
    "            self.filenames = filenames\n",
    "            self.n = len(self.filenames)\n",
    "            self.image_infos = image_infos if image_infos is not None else [None]*len(filenames)\n",
    "        else:\n",
    "            loaded = self.load_label(filenames)\n",
    "            self.labels = list(loaded.values())\n",
    "            self.filenames = list(loaded.keys())\n",
    "            self.n = len(self.filenames)\n",
    "            self.image_infos = [None]*self.n\n",
    "        self.indices = range(self.n)\n",
    "        self.albumentations = Albumentations()\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    def __getitem__(self, index):\n",
    "        index = self.indices[index]\n",
    "        temp_label = copy.deepcopy(self.labels[index])\n",
    "        \n",
    "        image,crop_index=self.load_image(index)\n",
    "        \n",
    "        crop_x, crop_y = crop_index\n",
    "        label=[]\n",
    "        #bbox 좌표를 YOLO 형식으로 변환: x_center, y_center, width, height (모두 0~1 정규화)\n",
    "        for i in range(len(temp_label)):\n",
    "            x = temp_label[i][1]  # bbox x\n",
    "            y = temp_label[i][2]  # bbox y  \n",
    "            w = temp_label[i][3]  # bbox width\n",
    "            h = temp_label[i][4]  # bbox height\n",
    "            \n",
    "            # 바운딩 박스가 크롭된 영역 내에 있는지 확인 (더 관대한 조건)\n",
    "            # 바운딩 박스의 중심점이 크롭 영역 내에 있으면 포함\n",
    "            center_x = x + w/2\n",
    "            center_y = y + h/2\n",
    "            \n",
    "            if (center_x >= crop_x and center_y >= crop_y and \n",
    "                center_x <= crop_x + self.input_size and center_y <= crop_y + self.input_size):\n",
    "                \n",
    "                # YOLO 형식으로 변환: (x_center, y_center, width, height) - 모두 0~1 사이 정규화\n",
    "                norm_x_center = (center_x - crop_x) / self.input_size\n",
    "                norm_y_center = (center_y - crop_y) / self.input_size\n",
    "                norm_width = w / self.input_size\n",
    "                norm_height = h / self.input_size\n",
    "                \n",
    "                # 정규화된 값들이 유효한 범위에 있는지 확인\n",
    "                if (0 <= norm_x_center <= 1 and 0 <= norm_y_center <= 1 and \n",
    "                    norm_width > 0 and norm_height > 0):\n",
    "                    \n",
    "                    # YOLO 형식: [class, x_center, y_center, width, height]\n",
    "                    converted_label = [temp_label[i][0], norm_x_center, norm_y_center, norm_width, norm_height]\n",
    "                    label.append(converted_label)\n",
    "\n",
    "        # 디버깅 정보 추가\n",
    "        # if len(label) == 0 and len(temp_label) > 0:\n",
    "        #     print(f\"Warning: 파일 {self.filenames[index]}에서 크롭 후 라벨이 없습니다. 원본 라벨 수: {len(temp_label)}\")\n",
    "        #     print(f\"크롭 정보: crop_x={crop_x}, crop_y={crop_y}, input_size={self.input_size}\")\n",
    "\n",
    "        cls=[]\n",
    "        box=[]\n",
    "        for i in range(len(label)):\n",
    "            cls.append(label[i][0])\n",
    "            box.append(label[i][1:5])\n",
    "        \n",
    "        # 클래스 인덱스를 0부터 시작하도록 변경 (1 -> 0)\n",
    "        cls=np.array(cls, dtype=np.float32)\n",
    "        if len(cls) > 0:\n",
    "            cls = cls - 1  # 1 -> 0 변환 (단일 클래스 detection)\n",
    "            cls = np.clip(cls, 0, len(self.params['names'])-1)  # 유효 범위로 클리핑\n",
    "        \n",
    "        box=np.array(box, dtype=np.float32)\n",
    "        nl = len(box)\n",
    "        \n",
    "        if self.augment and nl > 0:  # 라벨이 있을 때만 augmentation 적용\n",
    "            # Flip up-down\n",
    "            if random.random() < self.params['flip_ud']:\n",
    "                image = np.flipud(image).copy()\n",
    "                if nl:\n",
    "                    box[:, 1] = 1 - box[:, 1]  # y_center 반전\n",
    "            # Flip left-right\n",
    "            if random.random() < self.params['flip_lr']:\n",
    "                image = np.fliplr(image).copy()\n",
    "                if nl:\n",
    "                    box[:, 0] = 1 - box[:, 0]  # x_center 반전\n",
    "\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        # 빈 텐서 대신 적절한 크기의 인덱스 텐서 반환\n",
    "        return (torch.from_numpy(image).float(), \n",
    "                torch.from_numpy(cls).long(), \n",
    "                torch.from_numpy(box).float(), \n",
    "                torch.full((nl,), index, dtype=torch.long))\n",
    "\n",
    "    def load_image(self, i):\n",
    "        image = cv2.imread(self.filenames[i])\n",
    "        if image is None:\n",
    "            raise ValueError(f\"이미지를 불러올 수 없습니다: {self.filenames[i]}\")\n",
    "            \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR -> RGB 변환\n",
    "        h, w = image.shape[:2]\n",
    "        r = self.input_size / min(h, w)\n",
    "        \n",
    "        # 이미지가 input_size보다 큰 경우 (r < 1) -> 랜덤 크롭\n",
    "        if r < 1:\n",
    "            # 안전하게 크롭 범위 계산\n",
    "            max_h = max(0, h - self.input_size)\n",
    "            max_w = max(0, w - self.input_size)\n",
    "            h1 = random.randint(0, max_h) if max_h > 0 else 0\n",
    "            w1 = random.randint(0, max_w) if max_w > 0 else 0\n",
    "            image = image[h1:h1 + self.input_size, w1:w1 + self.input_size]\n",
    "        else:\n",
    "            # 이미지가 input_size보다 작거나 같은 경우 (r >= 1) -> 패딩\n",
    "            h1 = 0\n",
    "            w1 = 0\n",
    "            pad_image = np.ones((self.input_size, self.input_size, 3), dtype=np.uint8)*255  # 흰색 패딩\n",
    "            pad_image[:min(h,self.input_size), :min(w,self.input_size), :] = image[:min(h,self.input_size), :min(w,self.input_size), :]\n",
    "            image = pad_image\n",
    "        return image, (w1, h1)  # x, y 순서로 반환\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class Albumentations:\n",
    "    def __init__(self):\n",
    "        self.transform = None\n",
    "        try:\n",
    "            import albumentations\n",
    "\n",
    "            transforms = [albumentations.Blur(p=0.01),\n",
    "                          albumentations.CLAHE(p=0.01),\n",
    "                          albumentations.ToGray(p=0.01),\n",
    "                          albumentations.MedianBlur(p=0.01)]\n",
    "            self.transform = albumentations.Compose(transforms,\n",
    "                                                    albumentations.BboxParams('yolo', ['class_labels']))\n",
    "\n",
    "        except ImportError:  # package not installed, skip\n",
    "            pass\n",
    "\n",
    "    def __call__(self, image, box, cls):\n",
    "        if self.transform:\n",
    "            x = self.transform(image=image,\n",
    "                               bboxes=box,\n",
    "                               class_labels=cls)\n",
    "            image = x['image']\n",
    "            box = np.array(x['bboxes'])\n",
    "            cls = np.array(x['class_labels'])\n",
    "        return image, box, cls\n",
    "\n",
    "split=[0.9, 0.1]\n",
    "train_dataset=custom_dataset(filenames[:int(len(filenames)*split[0])],512, params, augment=True, labels=labels[:int(len(filenames)*split[0])])\n",
    "val_dataset = custom_dataset(filenames[int(len(filenames)*split[0]):],512, params, augment=False, labels=labels[int(len(filenames)*split[0]):])\n",
    "\n",
    "# 데이터셋 검증\n",
    "print(f\"전체 데이터: {len(filenames)}\")\n",
    "print(f\"훈련 데이터: {len(train_dataset)}\")\n",
    "print(f\"검증 데이터: {len(val_dataset)}\")\n",
    "\n",
    "# 샘플 데이터 확인\n",
    "sample_idx = 0\n",
    "sample_image, sample_cls, sample_box, sample_indices = train_dataset[sample_idx]\n",
    "print(f\"\\n샘플 데이터 확인:\")\n",
    "print(f\"이미지 크기: {sample_image.shape}\")\n",
    "print(f\"클래스 수: {len(sample_cls)}\")\n",
    "print(f\"바운딩 박스 수: {len(sample_box)}\")\n",
    "if len(sample_cls) > 0:\n",
    "    print(f\"클래스 범위: {sample_cls.min():.0f} ~ {sample_cls.max():.0f}\")\n",
    "if len(sample_box) > 0:\n",
    "    print(f\"바운딩 박스 좌표 범위: x_center={sample_box[:, 0].min():.3f}~{sample_box[:, 0].max():.3f}, y_center={sample_box[:, 1].min():.3f}~{sample_box[:, 1].max():.3f}\")\n",
    "    print(f\"바운딩 박스 크기 범위: width={sample_box[:, 2].min():.3f}~{sample_box[:, 2].max():.3f}, height={sample_box[:, 3].min():.3f}~{sample_box[:, 3].max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872981f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "참고: 데이터셋 크기(431)가 배치 크기(4)로 나누어 떨어지지 않습니다.\n",
      "마지막 배치는 3개의 샘플을 포함합니다.\n",
      "최종 훈련 배치 크기: 4\n",
      "최종 검증 배치 크기: 1\n"
     ]
    }
   ],
   "source": [
    "def collate_fn1(batch):\n",
    "    samples, cls, box, indices = zip(*batch)\n",
    "\n",
    "    cls = torch.cat(cls, dim=0)\n",
    "    box = torch.cat(box, dim=0)\n",
    "\n",
    "    new_indices = list(indices)\n",
    "    for i in range(len(indices)):\n",
    "        new_indices[i] += i\n",
    "    indices = torch.cat(new_indices, dim=0)\n",
    "\n",
    "    targets = {'cls': cls,\n",
    "                'box': box,\n",
    "                'idx': indices}\n",
    "    return torch.stack(samples, dim=0), targets\n",
    "\n",
    "\n",
    "# 모델 및 파라미터 준비\n",
    "model = nn.yolo_v11_m(len(params['names'])).to(device)\n",
    "optimizer = torch.optim.SGD(util.set_params(model, params['weight_decay']),\n",
    "                            params['max_lr'], params['momentum'], nesterov=True)\n",
    "criterion = util.ComputeLoss(model, params)\n",
    "\n",
    "# 데이터셋 및 데이터로드 (안전한 함수 사용)\n",
    "batch_size = 4\n",
    "# 안전하게 데이터로더 생성하는 함수\n",
    "def create_safe_loader(dataset, batch_size, is_train=True):\n",
    "    \"\"\"\n",
    "    배치 크기에 맞게 데이터셋을 조정하여 안전하게 데이터로더를 생성하는 함수\n",
    "    \"\"\"\n",
    "    dataset_size = len(dataset)\n",
    "    \n",
    "    # 배치 크기가 데이터셋 크기보다 큰 경우 배치 크기 조정\n",
    "    if dataset_size < batch_size:\n",
    "        print(f\"경고: 데이터셋 크기({dataset_size})가 배치 크기({batch_size})보다 작습니다. 배치 크기를 {dataset_size}로 조정합니다.\")\n",
    "        actual_batch_size = max(1, dataset_size)\n",
    "    else:\n",
    "        actual_batch_size = batch_size\n",
    "    \n",
    "    # 데이터셋이 배치 크기로 나누어 떨어지는지 확인\n",
    "    if dataset_size % actual_batch_size != 0:\n",
    "        print(f\"참고: 데이터셋 크기({dataset_size})가 배치 크기({actual_batch_size})로 나누어 떨어지지 않습니다.\")\n",
    "        print(f\"마지막 배치는 {dataset_size % actual_batch_size}개의 샘플을 포함합니다.\")\n",
    "    \n",
    "    # 데이터로더 생성\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        batch_size=actual_batch_size, \n",
    "        shuffle=is_train,\n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn1,\n",
    "        drop_last=(not is_train)  # 훈련 시에는 마지막 배치 유지, 검증 시에는 마지막 배치 제외\n",
    "    )\n",
    "    \n",
    "    return loader, actual_batch_size\n",
    "# 안전하게 데이터로더 생성\n",
    "loader, train_batch_size = create_safe_loader(train_dataset, batch_size, is_train=True)\n",
    "val_loader, val_batch_size = create_safe_loader(val_dataset, 1, is_train=False)\n",
    "\n",
    "print(f\"최종 훈련 배치 크기: {train_batch_size}\")\n",
    "print(f\"최종 검증 배치 크기: {val_batch_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3682b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient accumulation steps: 16\n",
      "단일 클래스 detection: cls loss는 0.500로 설정됨\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000 Training:   0%|          | 0/108 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3611.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Epoch 1/10000 | Memory: 1.927G | Box: 0.002 | Cls: 19.764 | DFL: 0.001: 100%|██████████| 108/108 [00:13<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10000 Results:\n",
      "  Train Loss - Box: 0.0022, Cls: 19.7636, DFL: 0.0013, Total: 19.7671\n",
      "  Validation - Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000\n",
      "  mAP@0.5: 0.0000, mAP@0.5:0.95: 0.0000\n",
      "  Cohen's Kappa: 0.0000 (Slight)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10000 | Memory: 1.927G | Box: 0.001 | Cls: 15.582 | DFL: 0.001: 100%|██████████| 108/108 [00:11<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10000 Results:\n",
      "  Train Loss - Box: 0.0010, Cls: 15.5815, DFL: 0.0005, Total: 15.5830\n",
      "  Validation - Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000\n",
      "  mAP@0.5: 0.0000, mAP@0.5:0.95: 0.0000\n",
      "  Cohen's Kappa: 0.0000 (Slight)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10000 | Memory: 2.257G | Box: 0.002 | Cls: 10.042 | DFL: 0.001: 100%|██████████| 108/108 [00:12<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10000 Results:\n",
      "  Train Loss - Box: 0.0021, Cls: 10.0424, DFL: 0.0012, Total: 10.0457\n",
      "  Validation - Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000\n",
      "  mAP@0.5: 0.0000, mAP@0.5:0.95: 0.0000\n",
      "  Cohen's Kappa: 0.0000 (Slight)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10000 | Memory: 2.257G | Box: 0.000 | Cls: 5.178 | DFL: 0.000: 100%|██████████| 108/108 [00:11<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10000 Results:\n",
      "  Train Loss - Box: 0.0004, Cls: 5.1783, DFL: 0.0003, Total: 5.1789\n",
      "  Validation - Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000\n",
      "  mAP@0.5: 0.0000, mAP@0.5:0.95: 0.0000\n",
      "  Cohen's Kappa: 0.0000 (Slight)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10000 | Memory: 2.257G | Box: 0.000 | Cls: 2.576 | DFL: 0.000:  61%|██████    | 66/108 [00:07<00:04, 10.13it/s]"
     ]
    }
   ],
   "source": [
    "from utils.valid import compute_validation_metrics, compute_validation_metrics_with_kappa, get_kappa_interpretation\n",
    "from utils.valid import visualize_ground_truth_and_prediction_separately\n",
    "from utils.valid import plot_training_progress\n",
    "\n",
    "\n",
    "# main.py의 train 함수를 참조한 개선된 학습 루프\n",
    "train_losses = []\n",
    "val_maps = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_map50s = []\n",
    "val_kappas = []  # Cohen's Kappa 추가\n",
    "epochs = 10000\n",
    "\n",
    "# 체크포인트 저장을 위한 디렉토리 생성\n",
    "save_dir = '../../model/binary_yolov11/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "#체크포인트 불러오기 \n",
    "# checkpoint_path = os.path.join(save_dir, 'best_model.pt')\n",
    "# if os.path.exists(checkpoint_path):\n",
    "#     checkpoint = torch.load(checkpoint_path, map_location=device,weights_only=False)\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "# main.py 스타일의 설정들\n",
    "best_map = 0\n",
    "accumulate = max(round(64 / batch_size), 1)  # gradient accumulation steps\n",
    "amp_scale = torch.amp.GradScaler()  # mixed precision scaler\n",
    "\n",
    "print(f\"Gradient accumulation steps: {accumulate}\")\n",
    "print(f\"단일 클래스 detection: cls loss는 {params['cls']:.3f}로 설정됨\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 훈련\n",
    "    model.train()\n",
    "    \n",
    "    # main.py 스타일의 평균 손실 추적\n",
    "    avg_box_loss = util.AverageMeter()\n",
    "    avg_cls_loss = util.AverageMeter()\n",
    "    avg_dfl_loss = util.AverageMeter()\n",
    "    \n",
    "    train_pbar = tqdm.tqdm(enumerate(loader), total=len(loader), desc=f'Epoch {epoch+1}/{epochs} Training')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, (images, targets) in train_pbar:\n",
    "        step = i + len(loader) * epoch\n",
    "        \n",
    "        # 타겟이 비어있는 배치 건너뛰기\n",
    "        if len(targets['cls']) == 0:\n",
    "            print(f\"Warning: 배치 {i}에 타겟이 없습니다. 건너뜁니다.\")\n",
    "            continue\n",
    "            \n",
    "        images = images.to(device).float() / 255\n",
    "        \n",
    "        # 타겟을 GPU로 이동\n",
    "        targets['cls'] = targets['cls'].to(device)\n",
    "        targets['box'] = targets['box'].to(device)\n",
    "        targets['idx'] = targets['idx'].to(device)\n",
    "        \n",
    "        # 타겟 검증\n",
    "        valid_indices = (targets['cls'] >= 0) & (targets['cls'] < len(params['names']))\n",
    "        if not valid_indices.all():\n",
    "            print(f\"Warning: 유효하지 않은 클래스 인덱스 발견: {targets['cls'][~valid_indices]}\")\n",
    "            # 유효한 타겟만 필터링\n",
    "            targets['cls'] = targets['cls'][valid_indices]\n",
    "            targets['box'] = targets['box'][valid_indices]\n",
    "            targets['idx'] = targets['idx'][valid_indices]\n",
    "        \n",
    "        # 다시 빈 타겟 체크\n",
    "        if len(targets['cls']) == 0:\n",
    "            print(f\"Warning: 필터링 후 배치 {i}에 유효한 타겟이 없습니다. 건너뜁니다.\")\n",
    "            continue\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(images)\n",
    "            loss_box, loss_cls, loss_dfl = criterion(outputs, targets)\n",
    "        \n",
    "        # Loss 검증 - NaN이나 무한대 값 체크\n",
    "        if torch.isnan(loss_box) or torch.isinf(loss_box):\n",
    "            print(f\"Warning: Box loss is NaN or Inf at step {step}\")\n",
    "            continue\n",
    "        if torch.isnan(loss_cls) or torch.isinf(loss_cls):\n",
    "            print(f\"Warning: Cls loss is NaN or Inf at step {step}\")\n",
    "            continue\n",
    "        if torch.isnan(loss_dfl) or torch.isinf(loss_dfl):\n",
    "            print(f\"Warning: DFL loss is NaN or Inf at step {step}\")\n",
    "            continue\n",
    "            \n",
    "        # 평균 손실 업데이트\n",
    "        avg_box_loss.update(loss_box.item(), images.size(0))\n",
    "        avg_cls_loss.update(loss_cls.item(), images.size(0))\n",
    "        avg_dfl_loss.update(loss_dfl.item(), images.size(0))\n",
    "        \n",
    "        # Loss scaling - 올바른 스케일링\n",
    "        total_loss = (loss_box + loss_cls + loss_dfl) / accumulate\n",
    "        \n",
    "        # Backward pass with gradient scaling\n",
    "        amp_scale.scale(total_loss).backward()\n",
    "        \n",
    "        # Gradient accumulation 및 optimization\n",
    "        if (step + 1) % accumulate == 0:\n",
    "            # Gradient clipping 추가\n",
    "            amp_scale.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "            \n",
    "            # Optimization step\n",
    "            amp_scale.step(optimizer)\n",
    "            amp_scale.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # GPU 메모리 동기화\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        # 진행률 표시 업데이트 - cls loss가 0이므로 간소화\n",
    "        if torch.cuda.is_available():\n",
    "            memory = f'{torch.cuda.memory_reserved() / 1E9:.4g}G'\n",
    "        else:\n",
    "            memory = 'N/A'\n",
    "        \n",
    "        # cls loss가 0이면 표시하지 않음\n",
    "        if params['cls'] > 0:\n",
    "            s = f'Memory: {memory} | Box: {avg_box_loss.avg:.3f} | Cls: {avg_cls_loss.avg:.3f} | DFL: {avg_dfl_loss.avg:.3f}'\n",
    "        else:\n",
    "            s = f'Memory: {memory} | Box: {avg_box_loss.avg:.3f} | DFL: {avg_dfl_loss.avg:.3f} (단일클래스)'\n",
    "        train_pbar.set_description(f'Epoch {epoch+1}/{epochs} | {s}')\n",
    "    \n",
    "    # 에폭 평균 손실 계산\n",
    "    avg_train_loss = avg_box_loss.avg + avg_cls_loss.avg + avg_dfl_loss.avg\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # 검증 (Cohen's Kappa 포함)\n",
    "    precision, recall, map50, mean_ap, kappa = compute_validation_metrics_with_kappa(\n",
    "        model, val_loader, device, params\n",
    "    )\n",
    "    val_maps.append(mean_ap)\n",
    "    val_precisions.append(precision)\n",
    "    val_recalls.append(recall)\n",
    "    val_map50s.append(map50)\n",
    "    val_kappas.append(kappa)\n",
    "    \n",
    "    # F1-score 계산\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # 결과 출력 - cls loss가 0이면 간소화\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs} Results:\")\n",
    "    if params['cls'] > 0:\n",
    "        print(f\"  Train Loss - Box: {avg_box_loss.avg:.4f}, Cls: {avg_cls_loss.avg:.4f}, DFL: {avg_dfl_loss.avg:.4f}, Total: {avg_train_loss:.4f}\")\n",
    "    else:\n",
    "        print(f\"  Train Loss - Box: {avg_box_loss.avg:.4f}, DFL: {avg_dfl_loss.avg:.4f}, Total: {avg_train_loss:.4f} (단일클래스)\")\n",
    "    print(f\"  Validation - Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}\")\n",
    "    print(f\"  mAP@0.5: {map50:.4f}, mAP@0.5:0.95: {mean_ap:.4f}\")\n",
    "    print(f\"  Cohen's Kappa: {kappa:.4f} ({get_kappa_interpretation(kappa)})\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # 베스트 모델 저장 (mAP 기준)\n",
    "    if mean_ap > best_map:\n",
    "        best_map = mean_ap\n",
    "        save_checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'amp_scale_state_dict': amp_scale.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'box_loss': avg_box_loss.avg,\n",
    "            'cls_loss': avg_cls_loss.avg,\n",
    "            'dfl_loss': avg_dfl_loss.avg,\n",
    "            'map': mean_ap,\n",
    "            'map50': map50,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'kappa': kappa,\n",
    "            'params': params\n",
    "        }\n",
    "        torch.save(save_checkpoint, os.path.join(save_dir, 'best_model.pt'))\n",
    "        print(f\"🎉 새로운 베스트 모델 저장! mAP: {mean_ap:.4f}, Kappa: {kappa:.4f}\")\n",
    "    \n",
    "    # 최신 모델도 저장 (main.py 스타일)\n",
    "    last_checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'amp_scale_state_dict': amp_scale.state_dict(),\n",
    "        'train_loss': avg_train_loss,\n",
    "        'box_loss': avg_box_loss.avg,\n",
    "        'cls_loss': avg_cls_loss.avg,\n",
    "        'dfl_loss': avg_dfl_loss.avg,\n",
    "        'map': mean_ap,\n",
    "        'map50': map50,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'kappa': kappa,\n",
    "        'params': params\n",
    "    }\n",
    "    torch.save(last_checkpoint, os.path.join(save_dir, 'last_model.pt'))\n",
    "    \n",
    "    # 100 에폭마다 학습 진행 그래프 생성 및 저장\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        try:\n",
    "            print(f\"\\n📊 Epoch {epoch+1} - 학습 진행 상황 그래프 생성 중...\")\n",
    "            plot_training_progress(train_losses, val_maps, val_precisions, val_recalls, val_map50s, epoch+1, save_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"그래프 생성 중 오류: {e}\")\n",
    "    \n",
    "    # 개선된 검증 이미지 시각화 (매 10 에폭마다) - 실제 라벨과 예측 라벨을 별도 figure로 표시\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        try:\n",
    "            # 여러 샘플에 대해 시각화\n",
    "            num_samples = 1 # 샘플 수를 1개\n",
    "            for sample_idx in range(num_samples):\n",
    "                print(f\"\\n📊 Epoch {epoch+1} - 검증 샘플 {sample_idx+1}/{num_samples}:\")\n",
    "                print(\"=\" * 60)\n",
    "                \n",
    "                # 실제 라벨과 예측 라벨을 별도 figure로 표시\n",
    "                sample_idx = random.randint(0, len(val_dataset)-1)\n",
    "                visualize_ground_truth_and_prediction_separately(\n",
    "                    model, val_dataset, idx=sample_idx, \n",
    "                    epoch=epoch+1, save_dir=save_dir\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"시각화 중 오류: {e}\")\n",
    "\n",
    "print(\"🎯 학습 완료!\")\n",
    "print(f\"최종 베스트 mAP: {best_map:.4f}\")\n",
    "print(f\"모델 저장 위치: {save_dir}\")\n",
    "print(f\"베스트 모델: {os.path.join(save_dir, 'best_model.pt')}\")\n",
    "print(f\"최신 모델: {os.path.join(save_dir, 'last_model.pt')}\")\n",
    "\n",
    "# 최종 성능 요약\n",
    "if val_kappas:\n",
    "    final_kappa = val_kappas[-1]\n",
    "    final_map = val_maps[-1]\n",
    "    final_precision = val_precisions[-1]\n",
    "    final_recall = val_recalls[-1]\n",
    "    final_f1 = 2 * (final_precision * final_recall) / (final_precision + final_recall) if (final_precision + final_recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n📊 최종 성능 요약:\")\n",
    "    print(f\"  mAP@0.5:0.95: {final_map:.4f}\")\n",
    "    print(f\"  Cohen's Kappa: {final_kappa:.4f} ({get_kappa_interpretation(final_kappa)})\")\n",
    "    print(f\"  F1-score: {final_f1:.4f}\")\n",
    "    print(f\"  Precision: {final_precision:.4f}\")\n",
    "    print(f\"  Recall: {final_recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
