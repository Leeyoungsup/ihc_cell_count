{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b39ece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import warnings\n",
    "from argparse import ArgumentParser\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from torch.utils import data\n",
    "# 개별 json 라벨 파일을 이용해 학습 데이터 리스트 생성\n",
    "from glob import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import os\n",
    "from nets import nn\n",
    "from utils import util\n",
    "from utils.dataset import Dataset\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import openslide\n",
    "import copy\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import math\n",
    "import numpy\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn.functional import cross_entropy\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\",device)\n",
    "params={'names':{\n",
    "  0: 'pd-l1 negative tumor cell',\n",
    "  1: 'pd-l1 positive tumor cell',\n",
    "  2: 'non-tumor cell'}}\n",
    "\n",
    "# params={'names':{\n",
    "#   0: 'pd-l1 negative tumor cell',\n",
    "#   1: 'pd-l1 positive tumor cell'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='../../model/yolov11/'\n",
    "model = nn.yolo_v11_m(len(params['names'])).to(device)\n",
    "checkpoint_path = os.path.join(save_dir, 'best_model.pt')\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device,weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "def wh2xy(x):\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else numpy.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y\n",
    "   \n",
    "def non_max_suppression(outputs, confidence_threshold=0.001, iou_threshold=0.65, class_thresholds=None):\n",
    "    \"\"\"\n",
    "    클래스별 개별 confidence threshold를 지원하는 NMS\n",
    "    \n",
    "    Args:\n",
    "        outputs: 모델 출력\n",
    "        confidence_threshold: 기본 confidence threshold (class_thresholds가 None일 때 사용)\n",
    "        iou_threshold: IoU threshold for NMS\n",
    "        class_thresholds: 클래스별 threshold 딕셔너리 {class_id: threshold}\n",
    "                         예: {0: 0.3, 1: 0.5, 2: 0.4}\n",
    "    \"\"\"\n",
    "    max_wh = 7680\n",
    "    max_det = 300\n",
    "    max_nms = 30000\n",
    "\n",
    "    bs = outputs.shape[0]  # batch size\n",
    "    nc = outputs.shape[1] - 4  # number of classes\n",
    "    \n",
    "    # 클래스별 threshold가 주어진 경우, 각 클래스에 대해 개별적으로 후보 선택\n",
    "    if class_thresholds is not None:\n",
    "        # 각 클래스별로 threshold 적용\n",
    "        class_candidates = []\n",
    "        for class_id in range(nc):\n",
    "            threshold = class_thresholds.get(class_id, confidence_threshold)\n",
    "            class_candidates.append(outputs[:, 4 + class_id] > threshold)\n",
    "        \n",
    "        # 모든 클래스 후보를 OR 연산으로 결합\n",
    "        xc = torch.stack(class_candidates, dim=1).any(dim=1)\n",
    "    else:\n",
    "        # 기존 방식: 모든 클래스에 동일한 threshold 적용\n",
    "        xc = outputs[:, 4:4 + nc].amax(1) > confidence_threshold\n",
    "\n",
    "    # Settings\n",
    "    start = time()\n",
    "    limit = 0.5 + 0.05 * bs  # seconds to quit after\n",
    "    output = [torch.zeros((0, 6), device=outputs.device)] * bs\n",
    "    \n",
    "    for index, x in enumerate(outputs):  # image index, image inference\n",
    "        x = x.transpose(0, -1)[xc[index]]  # confidence\n",
    "\n",
    "        # If none remain process next image\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # matrix nx6 (box, confidence, cls)\n",
    "        box, cls = x.split((4, nc), 1)\n",
    "        box = wh2xy(box)  # (cx, cy, w, h) to (x1, y1, x2, y2)\n",
    "        \n",
    "        if nc > 1:\n",
    "            # 클래스별 threshold 적용\n",
    "            if class_thresholds is not None:\n",
    "                valid_detections = []\n",
    "                for class_id in range(nc):\n",
    "                    threshold = class_thresholds.get(class_id, confidence_threshold)\n",
    "                    class_mask = cls[:, class_id] > threshold\n",
    "                    if class_mask.any():\n",
    "                        class_indices = torch.where(class_mask)[0]\n",
    "                        for idx in class_indices:\n",
    "                            valid_detections.append([\n",
    "                                box[idx], \n",
    "                                cls[idx, class_id], \n",
    "                                torch.tensor(class_id, device=x.device, dtype=torch.float)\n",
    "                            ])\n",
    "                \n",
    "                if valid_detections:\n",
    "                    boxes_list = [det[0] for det in valid_detections]\n",
    "                    confs_list = [det[1] for det in valid_detections]\n",
    "                    classes_list = [det[2] for det in valid_detections]\n",
    "                    \n",
    "                    x = torch.cat([\n",
    "                        torch.stack(boxes_list),\n",
    "                        torch.stack(confs_list).unsqueeze(1),\n",
    "                        torch.stack(classes_list).unsqueeze(1)\n",
    "                    ], dim=1)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                # 기존 방식\n",
    "                i, j = (cls > confidence_threshold).nonzero(as_tuple=False).T\n",
    "                x = torch.cat((box[i], x[i, 4 + j, None], j[:, None].float()), 1)\n",
    "        else:  # best class only\n",
    "            conf, j = cls.max(1, keepdim=True)\n",
    "            threshold = class_thresholds.get(0, confidence_threshold) if class_thresholds else confidence_threshold\n",
    "            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > threshold]\n",
    "\n",
    "        # Check shape\n",
    "        n = x.shape[0]  # number of boxes\n",
    "        if not n:  # no boxes\n",
    "            continue\n",
    "        x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence and remove excess boxes\n",
    "\n",
    "        # Batched NMS\n",
    "        c = x[:, 5:6] * max_wh  # classes\n",
    "        boxes, scores = x[:, :4] + c, x[:, 4]  # boxes, scores\n",
    "        indices = torchvision.ops.nms(boxes, scores, iou_threshold)  # NMS\n",
    "        indices = indices[:max_det]  # limit detections\n",
    "\n",
    "        output[index] = x[indices]\n",
    "        if (time() - start) > limit:\n",
    "            break  # time limit exceeded\n",
    "\n",
    "    return output\n",
    "    \n",
    "def pred_patch(torch_patch, model, start_x, start_y,magnification):\n",
    "    model.eval()\n",
    "    # 클래스별 개별 confidence threshold 설정\n",
    "    class_thresholds = {\n",
    "        0: 0.7,  # pd-l1 negative tumor cell - 낮은 threshold (더 많이 검출)\n",
    "        1: 0.3,  # pd-l1 positive tumor cell - 높은 threshold (정확한 검출)\n",
    "        2: 0.4   # non-tumor cell - 중간 threshold\n",
    "    }\n",
    "    iou_threshold=0.8\n",
    "    prediction_count = 0\n",
    "    negative_tumor=[]\n",
    "    positive_tumor=[]\n",
    "    non_tumor=[]\n",
    "    with torch.no_grad():\n",
    "        img_input = torch_patch\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            pred = model(img_input)\n",
    "        \n",
    "        # 클래스별 threshold를 사용하는 NMS 적용\n",
    "        results = non_max_suppression(pred, confidence_threshold=0.5, iou_threshold=iou_threshold, class_thresholds=class_thresholds)\n",
    "        \n",
    "        if len(results[0]) > 0:\n",
    "            for *xyxy, conf, cls_id in results[0]:\n",
    "                x1, y1, x2, y2 = xyxy\n",
    "                x1, y1, x2, y2 = x1.item(), y1.item(), x2.item(), y2.item()\n",
    "                w_pred = x2 - x1\n",
    "                h_pred = y2 - y1\n",
    "                center_x = (x1 + x2)//2\n",
    "                center_y = (y1 + y2)//2\n",
    "                if cls_id.item() == 0: #pd-l1 negative tumor cell\n",
    "                    negative_tumor.append({'x':start_x+center_x*magnification,'y':start_y+center_y*magnification,'cls_id':0})\n",
    "                elif cls_id.item() == 1: #pd-l1 positive tumor cell\n",
    "                    positive_tumor.append({'x':start_x+center_x*magnification,'y':start_y+center_y*magnification,'cls_id':1})\n",
    "                else: #non-tumor cell\n",
    "                    non_tumor.append({'x':start_x+center_x*magnification,'y':start_y+center_y*magnification,'cls_id':2})\n",
    "\n",
    "                \n",
    "                prediction_count += 1\n",
    "    return negative_tumor, positive_tumor, non_tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eb2b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_asap_xml(negative_tumor, positive_tumor, non_tumor, output_path):\n",
    "    \"\"\"\n",
    "    세포 검출 결과를 ASAP XML 형식으로 저장하는 함수\n",
    "    \n",
    "    Args:\n",
    "        negative_tumor: PD-L1 negative tumor cells 리스트\n",
    "        positive_tumor: PD-L1 positive tumor cells 리스트  \n",
    "        non_tumor: Non-tumor cells 리스트\n",
    "        output_path: 저장할 XML 파일 경로\n",
    "    \"\"\"\n",
    "    \n",
    "    # 루트 엘리먼트 생성\n",
    "    root = ET.Element(\"ASAP_Annotations\")\n",
    "    \n",
    "    # Annotations 엘리먼트 생성\n",
    "    annotations = ET.SubElement(root, \"Annotations\")\n",
    "    \n",
    "    annotation_id = 0\n",
    "    \n",
    "    # Negative tumor cells 추가 (빨간색)\n",
    "    for cell in negative_tumor:\n",
    "        annotation = ET.SubElement(annotations, \"Annotation\")\n",
    "        annotation.set(\"Name\", f\"Annotation {annotation_id}\")\n",
    "        annotation.set(\"Type\", \"Dot\")\n",
    "        annotation.set(\"PartOfGroup\", \"Negative Tumor\")\n",
    "        annotation.set(\"Color\", \"#FF0000\")  # 빨간색\n",
    "        \n",
    "        coordinates = ET.SubElement(annotation, \"Coordinates\")\n",
    "        coordinate = ET.SubElement(coordinates, \"Coordinate\")\n",
    "        coordinate.set(\"Order\", \"0\")\n",
    "        coordinate.set(\"X\", str(float(cell['x'])))\n",
    "        coordinate.set(\"Y\", str(float(cell['y'])))\n",
    "        \n",
    "        annotation_id += 1\n",
    "    \n",
    "    # Positive tumor cells 추가 (파란색)\n",
    "    for cell in positive_tumor:\n",
    "        annotation = ET.SubElement(annotations, \"Annotation\")\n",
    "        annotation.set(\"Name\", f\"Annotation {annotation_id}\")\n",
    "        annotation.set(\"Type\", \"Dot\")\n",
    "        annotation.set(\"PartOfGroup\", \"Positive Tumor\")\n",
    "        annotation.set(\"Color\", \"#0000FF\")  # 파란색\n",
    "        \n",
    "        coordinates = ET.SubElement(annotation, \"Coordinates\")\n",
    "        coordinate = ET.SubElement(coordinates, \"Coordinate\")\n",
    "        coordinate.set(\"Order\", \"0\")\n",
    "        coordinate.set(\"X\", str(float(cell['x'])))\n",
    "        coordinate.set(\"Y\", str(float(cell['y'])))\n",
    "        \n",
    "        annotation_id += 1\n",
    "    \n",
    "    # Non-tumor cells 추가 (녹색)\n",
    "    # for cell in non_tumor:\n",
    "    #     annotation = ET.SubElement(annotations, \"Annotation\")\n",
    "    #     annotation.set(\"Name\", f\"Annotation {annotation_id}\")\n",
    "    #     annotation.set(\"Type\", \"Dot\")\n",
    "    #     annotation.set(\"PartOfGroup\", \"Non Tumor\")\n",
    "    #     annotation.set(\"Color\", \"#00FF00\")  # 녹색\n",
    "        \n",
    "    #     coordinates = ET.SubElement(annotation, \"Coordinates\")\n",
    "    #     coordinate = ET.SubElement(coordinates, \"Coordinate\")\n",
    "    #     coordinate.set(\"Order\", \"0\")\n",
    "    #     coordinate.set(\"X\", str(float(cell['x'])))\n",
    "    #     coordinate.set(\"Y\", str(float(cell['y'])))\n",
    "        \n",
    "    #     annotation_id += 1\n",
    "    \n",
    "    # AnnotationGroups 엘리먼트 생성\n",
    "    annotation_groups = ET.SubElement(root, \"AnnotationGroups\")\n",
    "    \n",
    "    # Negative Tumor 그룹\n",
    "    group1 = ET.SubElement(annotation_groups, \"Group\")\n",
    "    group1.set(\"Name\", \"Negative Tumor\")\n",
    "    group1.set(\"PartOfGroup\", \"None\")\n",
    "    group1.set(\"Color\", \"#0000FF\")\n",
    "    attributes1 = ET.SubElement(group1, \"Attributes\")\n",
    "    \n",
    "    # Positive Tumor 그룹\n",
    "    group2 = ET.SubElement(annotation_groups, \"Group\")\n",
    "    group2.set(\"Name\", \"Positive Tumor\")\n",
    "    group2.set(\"PartOfGroup\", \"None\")\n",
    "    group2.set(\"Color\", \"#FF0000\")\n",
    "    attributes2 = ET.SubElement(group2, \"Attributes\")\n",
    "    \n",
    "    # Non Tumor 그룹\n",
    "    # group3 = ET.SubElement(annotation_groups, \"Group\")\n",
    "    # group3.set(\"Name\", \"Non Tumor\")\n",
    "    # group3.set(\"PartOfGroup\", \"None\")\n",
    "    # group3.set(\"Color\", \"#00FF00\")\n",
    "    # attributes3 = ET.SubElement(group3, \"Attributes\")\n",
    "    \n",
    "    # XML을 예쁘게 포맷팅하여 저장\n",
    "    rough_string = ET.tostring(root, 'unicode')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    pretty_xml = reparsed.toprettyxml(indent=\"\t\")\n",
    "    \n",
    "    # <?xml version... 라인을 원하는 형태로 수정\n",
    "    lines = pretty_xml.split('\\n')\n",
    "    lines[0] = '<?xml version=\"1.0\"?>'\n",
    "    pretty_xml = '\\n'.join(lines[1:])  # 빈 라인 제거\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(pretty_xml)\n",
    "    \n",
    "    print(f\"XML 파일이 저장되었습니다: {output_path}\")\n",
    "    print(f\"총 검출된 세포 수:\")\n",
    "    print(f\"  - Negative tumor cells: {len(negative_tumor)}개\")\n",
    "    print(f\"  - Positive tumor cells: {len(positive_tumor)}개\") \n",
    "    print(f\"  - Non-tumor cells: {len(non_tumor)}개\")\n",
    "    print(f\"  - 전체: {len(negative_tumor) + len(positive_tumor) + len(non_tumor)}개\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2021d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [05:49<00:00,  1.67s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML 파일이 저장되었습니다: ../../results/WSI_IHC_nuclei_detection/CODIPAI-STER-SS-00171-I-HR-01.xml\n",
      "총 검출된 세포 수:\n",
      "  - Negative tumor cells: 82493개\n",
      "  - Positive tumor cells: 127944개\n",
      "  - Non-tumor cells: 0개\n",
      "  - 전체: 210437개\n"
     ]
    }
   ],
   "source": [
    "import pyvips\n",
    "slide_path=glob('../../data/WSI_test/*.ndpi')\n",
    "image_size=512 # 모델 입력 크기\n",
    "origin_mpp=0.25\n",
    "output_mpp=0.5\n",
    "original_size=int(image_size*output_mpp/origin_mpp) #1122\n",
    "magnification=original_size/image_size\n",
    "count=0\n",
    "# for i in tqdm(range(len(slide_path))):\n",
    "i=0\n",
    "file_name=os.path.basename(slide_path[i]).split('.')[0]\n",
    "slide=openslide.OpenSlide(slide_path[i])\n",
    "thumbnail=slide.get_thumbnail((slide.dimensions[0]//64, slide.dimensions[1]//64))\n",
    "slide = pyvips.Image.new_from_file(slide_path[i])\n",
    "\n",
    "thumb_mask=cv2.threshold(255-np.array(thumbnail.convert('L')),30,255,cv2.THRESH_BINARY)[1]\n",
    "thumb_mask=cv2.morphologyEx(thumb_mask,cv2.MORPH_CLOSE,np.ones((15,15),np.uint8))\n",
    "thumb_mask=cv2.morphologyEx(thumb_mask,cv2.MORPH_OPEN,np.ones((5,5),np.uint8))\n",
    "negative_tumor=[]\n",
    "positive_tumor=[]\n",
    "non_tumor=[]\n",
    "for patch_row in tqdm(range(slide.width//image_size-1)):\n",
    "    for patch_col in range(slide.height//image_size-1):\n",
    "        if np.sum(thumb_mask[(patch_col*image_size)//64:((patch_col+1)*image_size)//64,(patch_row*image_size)//64:((patch_row+1)*image_size)//64])>0:\n",
    "            count+=1\n",
    "            patch=slide.crop(patch_row*image_size, patch_col*image_size, image_size, image_size)\n",
    "            patch=np.ndarray(buffer=patch.write_to_memory(),\n",
    "                        dtype=np.uint8,\n",
    "                        shape=[patch.height, patch.width, patch.bands])\n",
    "            torch_patch=torch.from_numpy(np.array(patch)[:,:,:3]).permute(2,0,1).unsqueeze(0).float()/255.\n",
    "            torch_patch=torch_patch.to(device)\n",
    "            temp_negative_tumor, temp_positive_tumor, temp_non_tumor = pred_patch(torch_patch, model, patch_row*image_size, patch_col*image_size, 1)\n",
    "            negative_tumor.extend(temp_negative_tumor)\n",
    "            positive_tumor.extend(temp_positive_tumor)\n",
    "            # non_tumor.extend(temp_non_tumor)\n",
    "# XML 파일 생성\n",
    "output_xml_path = f\"../../results/WSI_IHC_nuclei_detection/{file_name}.xml\"\n",
    "os.makedirs(\"../../results/WSI_IHC_nuclei_detection\", exist_ok=True)\n",
    "\n",
    "create_asap_xml(negative_tumor, positive_tumor, non_tumor, output_xml_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
